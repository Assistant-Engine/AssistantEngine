@page "/"
@using System.ComponentModel
@using AssistantEngine.Factories
@using AssistantEngine.Services.Extensions
@using AssistantEngine.Services.Implementation
@using AssistantEngine.UI.Services
@using AssistantEngine.UI.Services.Implementation.Database
@using AssistantEngine.UI.Services.Implementation.Factories
@using AssistantEngine.UI.Services.Implementation.Models.Chat
@using AssistantEngine.UI.Services.Models
@using AssistantEngine.UI.Services.Models.Chat
@using static AssistantEngine.Services.Extensions.ChatMessageExtensions;

@inject NavigationManager Nav
@inject SemanticSearch Search
@implements IDisposable
@inject ChatClientState ClientState
@inject IDatabaseRegistry DbRegistry
@inject IAppHealthService Health
@inject ChatClientFactory ChatFactory
@inject ChatClientState State
@inject IJSRuntime JSRuntime
@inject IChatRepository ChatRepository

<PageTitle>Assistant Engine - Chat</PageTitle>

<Sidebar CurrentSession="@chatSession"
         CurrentSessionChanged="OnSessionChanged"  
         OpenSettingsModalRequested="OpenSettingsModal" />

<OllamaImportModal @ref="_importModal" />
<GlobalSettingsModal @ref="_settingsModal" />


<div id="chat-container-outer">

    <div class="chat-container-inner">
        
        <ChatHeader @ref="header" OnToggleEvaluations="ToggleEvaluations" OpenModalRequested="OpenImportModal" OnStateChange="@SwitchModel" OnNewChat="@ResetConversationAsync" OnStateSelected="SwitchModel2" OnToggleSidebar="ToggleSidebar" IsSidebarVisible="@showSidebar" />

        @if (!isIngesting)
        {
            <ChatMessageList Messages="@messages" ChatResponse="@chatResponse" InProgressMessage="@currentResponseMessage" IsLoading="@isLoading" IsStreaming="@isStreaming" OnEditSubmit="@OnUserEditSubmit">
                <NoMessagesContent>
                    <img src="_content/AssistantEngine.UI/img/logo.svg" id="inner-logo-main" />
                    @*<div class="description-text-1">@ClientState.Config.Description</div>@*
                    @*<div>Tools @(chatOptions?.Tools?.Any() == true ? string.Join(", ", chatOptions.Tools.Select(x => x.Name)) : "No tools available")</div>*@


                    @*<ChatCitation File="Example_Emergency_Survival_Kit.pdf" />
                    <ChatCitation File="Example_GPS_Watch.pdf" />*@
                </NoMessagesContent>
            </ChatMessageList>
        }
        else
        {
            <LoadingSpinner Visible="@isIngesting" Message="Ingesting Data..." />

        }
      
        <div id="chat-container" class="chat-container">
           <ChatSuggestions OnSelected="@AddUserMessageAsync" @ref="@chatSuggestions" />
            <ChatInput OnSend="@AddUserMessageAsync" @ref="@chatInput" />

        </div>
    </div>
    @if (showSidebar)
    {
        <ChatOptionsSidebar OnStateChange="@SwitchModel" AssistantConfig="@ClientState.Config" class="order-last" />
    }

   </div>

@code {
    private ChatHeader? header;
    private OllamaImportModal? _importModal;
    private GlobalSettingsModal? _settingsModal;
    private DotNetObjectReference<Chat>? _ref;
    Dictionary<string, IDatabase> databaseDict;
    private AppHealthSnapshot _health;
    private EventHandler<AppHealthSnapshot>? _healthHandler;
    ChatSession chatSession = new();
    private List<ChatMessage> messages = new();


    private void ToggleEvaluations()
    {

    }
    private async Task SwitchModel()
    {
        await ChatRepository.SaveAsync(chatSession);
        await OnParametersSetAsync();
        await InvokeAsync(StateHasChanged);

    }
    private void OpenSettingsModal() => _settingsModal?.Open();
    private void OpenImportModal() => _importModal?.OpenDownloadModal();
    private void SetupChatState()
    {
        databaseDict = DbRegistry.All.ToDictionary(x => x.Key, x => x.Value);

        // only add system prompt once
        if (messages.Count > 0)
        {
            messages.Clear();
        }

        if (messages.Count == 0)
            messages.Add(new(ChatRole.System, State.Config.SystemPrompt));

        Console.WriteLine(chatOptions.Tools);
    }


    private async Task SwitchModel2()
    {


    }

    // NEW: stream tokens into currentResponseMessage in real time
    private async Task GenerateAssistantResponseStreamingAsync(List<ChatMessage> filteredMessages)
    {
        currentResponseCancellation?.Dispose();
        currentResponseCancellation = new();
        isLoading = true;

        // wall-clock start
        var startTime = DateTime.UtcNow;
        DateTime? firstTokenTime = null;

        // prepare the in-progress assistant message (bound to ChatMessageList via InProgressMessage)
        currentResponseMessage = new ChatMessage
        {
            MessageId = Guid.NewGuid().ToString(),
            Role = ChatRole.Assistant
        };

        try
        {
            var updatesBuffer = new List<ChatResponseUpdate>();
            var mergedAdditional = new Microsoft.Extensions.AI.AdditionalPropertiesDictionary();

            await foreach (var update in ChatClient
                .GetStreamingResponseAsync(filteredMessages, chatOptions, currentResponseCancellation.Token)
                .ConfigureAwait(false))
            {
                isStreaming = true;
                updatesBuffer.Add(update);

                // merge AdditionalProperties as they arrive (last-write-wins)
                if (update?.AdditionalProperties is not null)
                    foreach (var kv in update.AdditionalProperties)
                        mergedAdditional[kv.Key] = kv.Value;

                var contents = update?.Contents ?? [];
                foreach (var c in contents)
                {
                    // mark first token time on first piece of content (text or otherwise)
                    if (!firstTokenTime.HasValue) firstTokenTime = DateTime.UtcNow;

                    if (c is TextContent tc)
                    {
                        var lastText = currentResponseMessage!.Contents.OfType<TextContent>().LastOrDefault();
                        if (lastText is null) currentResponseMessage!.Contents.Add(new TextContent(tc.Text));
                        else lastText.Text += tc.Text;
                    }
                    else
                    {
                        currentResponseMessage!.Contents.Add(c);
                        if (c.GetType().Name.Contains("ToolCall", StringComparison.OrdinalIgnoreCase))
                            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", "Running tool…", "Tools");
                        if (c.GetType().Name.Contains("ToolResult", StringComparison.OrdinalIgnoreCase))
                            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", "Tool finished.", "Tools");
                    }

                    ChatMessageItem.NotifyChanged(currentResponseMessage!);
                }

                await InvokeAsync(StateHasChanged);
            }

            // build ChatResponse from updates
            async IAsyncEnumerable<ChatResponseUpdate> Replay()
            {
                foreach (var u in updatesBuffer) yield return u;
            }
            chatResponse = await Replay().ToChatResponseAsync(currentResponseCancellation.Token);

            // --- ensure AdditionalProperties contains required durations as per your definitions ---
            chatResponse.AdditionalProperties ??= new Microsoft.Extensions.AI.AdditionalPropertiesDictionary();

            // merge what we collected during streaming
            foreach (var kv in mergedAdditional)
                chatResponse.AdditionalProperties[kv.Key] = kv.Value;

            var finishTime = DateTime.UtcNow;
            var totalAll = finishTime - startTime;

            // total_duration_all: whole wall time
            if (!chatResponse.AdditionalProperties.ContainsKey("total_duration_all"))
                chatResponse.AdditionalProperties["total_duration_all"] = totalAll;

            // load_duration: start -> first token (or totalAll if no tokens ever arrived)
            var loadDuration = firstTokenTime.HasValue ? (firstTokenTime.Value - startTime) : totalAll;
            if (!chatResponse.AdditionalProperties.ContainsKey("load_duration"))
                chatResponse.AdditionalProperties["load_duration"] = loadDuration;

            // eval_duration: first token -> finish (zero if no tokens)
            var evalDuration = firstTokenTime.HasValue ? (finishTime - firstTokenTime.Value) : TimeSpan.Zero;
            if (!chatResponse.AdditionalProperties.ContainsKey("eval_duration"))
                chatResponse.AdditionalProperties["eval_duration"] = evalDuration;

            // total_duration (model time): if missing, use eval_duration
            if (!chatResponse.AdditionalProperties.ContainsKey("total_duration"))
                chatResponse.AdditionalProperties["total_duration"] = evalDuration;

            // tool_duration: keep your existing approach (total_all - total_duration), never negative
            if (!chatResponse.AdditionalProperties.ContainsKey("tool_duration"))
            {
                var toolDuration = TimeSpan.Zero;
                chatResponse.AdditionalProperties["tool_duration"] = toolDuration;
            }
            // --- end ensure durations ---

            messages.Add(currentResponseMessage!);
            chatSession.Messages = messages;
            currentResponseMessage = null;
            isStreaming = false;
            isLoading = false;

            chatSuggestions?.Update(messages);
            await ChatRepository.SaveAsync(chatSession);

            if (chatSession.DefaultTitle())
                await SetChatMessageTitle();
        }
        catch (OperationCanceledException)
        {
            isLoading = false;
        }
        catch (Exception ex)
        {
            isLoading = false;
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", ex.Message, "Streaming");
        }
    }



    private IChatClient ChatClient => ChatFactory(State.Config.AssistantModel.ModelId);
    private IChatClient MiniClient => ChatFactory(State.Config.MiniTaskModel.ModelId);
    AssistantConfig CurrentConfig => ClientState.Config;
    private bool isIngesting => !ClientState.IngestionFinished;
    //IChatClient ChatClient => (IChatClient) ClientState.Client; testing with this removed


    protected override void OnInitialized()
    {
        ClientState.OnLoaderMessage += (v, m) =>
        {
       
            InvokeAsync(StateHasChanged);
        };
    }

    private async Task OnSessionChanged(ChatSession session)
    {
        CancelAnyCurrentResponse();
        chatSession = session;
        messages = chatSession.Messages?.ToList() ?? new List<ChatMessage>();

        //ok

        await InvokeAsync(StateHasChanged);
      
    }
    private ChatOptions chatOptions => ClientState.ChatOptions;

    private CancellationTokenSource? currentResponseCancellation;
    private ChatMessage? currentResponseMessage;
    private ChatResponse? chatResponse;
    private ChatInput? chatInput;
    private ChatSuggestions? chatSuggestions;


    private bool showSidebar = false;
    private bool isLoading = false;
    private bool isStreaming = false;

    private void ToggleSidebar()
    {
        showSidebar = !showSidebar;

    }


    // — then call it here (and drop OnInitialized entirely)
    // — then call it here (and drop OnInitialized entirely)
    protected override async Task OnParametersSetAsync()
    {
        try
        {
            SetupChatState();
            // await base.OnParametersSetAsync();
            await base.OnParametersSetAsync();
        }
        catch (Exception ex)
        {
            Console.WriteLine(ex.Message);
            Console.WriteLine(ex.StackTrace);
        }

    }

    protected override async Task OnInitializedAsync()
    {
        _health = Health.Snapshot;

        await State.ChangeModelAsync();
        await InvokeAsync(StateHasChanged);

        await base.OnInitializedAsync();
    }


    private OllamaSharp.Models.Model currentModel;
    // NEW: centralize assistant generation so edits can reuse it
    private async Task GenerateAssistantResponseAsync(List<ChatMessage> filteredMessages)
    {
        //currentResponseCancellation ??= new();
        currentResponseCancellation?.Dispose();
        currentResponseCancellation = new();   // ✅ always fresh
        DateTime startTime = DateTime.UtcNow;


        
        var response = await ChatClient.GetResponseAsync(filteredMessages, chatOptions, currentResponseCancellation.Token);
        var merged = new List<ChatMessage>();
        ChatMessage? buffer = null;

        foreach (var m in response.Messages)
        {
            if (m.Role == ChatRole.Assistant)
            {
                if (buffer == null)
                {
                    buffer = new ChatMessage
                    {
                        MessageId = Guid.NewGuid().ToString(),
                        Role = ChatRole.Assistant
                    };
                    foreach (var c in m.Contents ?? Enumerable.Empty<AIContent>())
                        buffer.Contents.Add(c);
                }
                else
                {
                    foreach (var c in m.Contents ?? Enumerable.Empty<AIContent>())
                        buffer.Contents.Add(c);
                }
            }
            else if (m.Role == ChatRole.User)
            {
                if (buffer != null) { merged.Add(buffer); buffer = null; }
                merged.Add(new ChatMessage
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Role = m.Role,
                    Contents = new List<AIContent>(m.Contents ?? [])
                });
            }
            else
            {
                merged.Add(new ChatMessage
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Role = m.Role,
                    Contents = new List<AIContent>(m.Contents ?? [])
                });
            }
        }
        if (buffer != null) merged.Add(buffer);

        foreach (var mm in merged)
        {
            if (string.IsNullOrEmpty(mm.MessageId) || messages.Any(x => x.MessageId == mm.MessageId))
                mm.MessageId = Guid.NewGuid().ToString();

            messages.Add(mm.Clone());
        }

        DateTime finishTime = DateTime.UtcNow;
        TimeSpan duration = finishTime - startTime;
        if (response.AdditionalProperties != null)
        {
            response.AdditionalProperties.Add("total_duration_all", duration);
            if (response.AdditionalProperties.TryGetValue("total_duration", out var td) && TimeSpan.TryParse(td?.ToString(), out var totalDurationAnalysis))
                response.AdditionalProperties.Add("tool_duration", duration - totalDurationAnalysis);
        }

        isLoading = false;

        chatSession.Messages = messages;
        chatResponse = response;

        if (chatSession.DefaultTitle())
            await SetChatMessageTitle();

        chatSuggestions?.Update(messages);
        await ChatRepository.SaveAsync(chatSession);
    }

    // UPDATED: use the helper above
    private async Task AddUserMessageAsync(ChatMessage userMessage)
    {
        var o = Health.Get(HealthDomain.Ollama);
        if (o.Level != HealthLevel.Healthy)
        {
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", o.Error ?? "Ollama not reachable.", "Chat");
            return;
        }

        CancelAnyCurrentResponse();

        messages.Add(userMessage);
        chatSuggestions?.Clear();
        await chatInput!.FocusAsync();

        currentResponseCancellation = new();
        isLoading = true;
        await InvokeAsync(StateHasChanged);

        var filteredMessages = FilterChatMessages(messages);
         await GenerateAssistantResponseStreamingAsync(filteredMessages);
    }

    // NEW: handle inline user-message edit → truncate future → regenerate
    private async Task OnUserEditSubmit((ChatMessage message, string newText) edit)
    {
        var (msg, newText) = edit;

        CancelAnyCurrentResponse();

        var idx = messages.FindIndex(m => m.MessageId == msg.MessageId);
        if (idx < 0) idx = messages.IndexOf(msg);
        if (idx < 0) return;

        // update the edited user message
        messages[idx] = new (ChatRole.User, newText);
        try
        {
           // messages[idx].Contents?.Clear();
           // messages[idx].Contents?.Add(new TextContent(newText));
        }
        catch { /* safe no-op if types differ */ }

        // drop everything after the edited message
        if (idx < messages.Count - 1)
            messages.RemoveRange(idx + 1, messages.Count - (idx + 1));

        chatResponse = null;
        isLoading = true;
        await InvokeAsync(StateHasChanged);

        var filtered = FilterChatMessages(messages);
        await GenerateAssistantResponseStreamingAsync(filtered);
    }

    private List<ChatMessage> FilterChatMessages(List<ChatMessage> messagesToFilter)
    {
        var filteredMessages = messagesToFilter;
        ChatOptions chatOptions = new ChatOptions();


        if (!State.Config.PersistThoughtHistory)
        {
            filteredMessages.RemoveThinkMessages();
        }

        return filteredMessages;
    }


    private async Task SetChatMessageTitle()
    {
        try
        {
            var miniOptions = ClientState.Config.ModelOptions.First(m => m.Key == "MiniTask").Options;
            List<ChatMessage> messagesx = new();
            string prompt = $"Output a maximum three word title for text you receive. Only ever output these words.";
            string userMessage = messages.First(x => x.Role == ChatRole.User).Text;
            messagesx.Add(new(ChatRole.System, prompt));
            messagesx.Add(new(ChatRole.User, userMessage));
            var response = await MiniClient.GetResponseAsync(messagesx, miniOptions);
            string title = ChatMessageExtensions.RemoveThinkTags(response.Messages.First(x => x.Role == ChatRole.Assistant).Text);
            chatSession.Title = title;
            await ChatRepository.SaveAsync(chatSession);
            await InvokeAsync(StateHasChanged);
        }catch(Exception ex)
        {
            Console.WriteLine("Error Setting Chat Message Title");
            Console.WriteLine(ex.Message);
            Console.WriteLine(ex.StackTrace);
        }

    }



    private Task SwitchModel(OllamaSharp.Models.Model model)
    {
        currentModel = model;
        // maybe restart the chat or just show the new model name
        return Task.CompletedTask;
    }
    private void CancelAnyCurrentResponse()
    {
        // If a response was cancelled while streaming, include it in the conversation so it's not lost
        if (currentResponseMessage is not null)
        {
            messages.Add(currentResponseMessage);
        }
        isLoading = false;
        chatResponse = null;
        currentResponseCancellation?.Cancel();
        currentResponseMessage = null;
    }

    private async Task ResetConversationAsync() //clear active here
    {
        try{
            chatSession = new();
            CancelAnyCurrentResponse();
            messages.Clear();
            messages.Add(new(ChatRole.System, State.Config.SystemPrompt));
            chatSuggestions?.Clear(); chatResponse = null;
            await chatInput!.FocusAsync();
        }catch(Exception ex)
        {
            Console.WriteLine(ex.Message);Console.WriteLine(ex.StackTrace);
        }

    }
    private void OnStatusMessageHandler(string msg)
    {
        _ = ShowToastAsync(msg); // fire-and-forget
    }

    private async Task ShowToastAsync(string msg)
    {
        try
        {
            if (msg.StartsWith("TOAST|", StringComparison.Ordinal))
            {
                var parts = msg.Split('|', 4);
                var level = parts.Length > 1 ? parts[1] : "info";      // info|success|warning|error
                var title = parts.Length > 2 ? parts[2] : "Notification";
                var body = parts.Length > 3 ? parts[3] : "";

                await JSRuntime.InvokeVoidAsync($"GLOBAL.toastrInterop.{level}", body, title);
            }
            else
            {
                await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", msg, "Info");
            }
        }
        catch (Exception ex) { await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", ex.Message, "Error"); }
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            State.OnStatusMessage -= OnStatusMessageHandler;
            State.OnStatusMessage += OnStatusMessageHandler;
            _ref ??= DotNetObjectReference.Create(this);
         //   ClientState.OnChatLoaderMessage += async (_, msg) =>
//{
         //   if (!string.IsNullOrWhiteSpace(msg))
         //           await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", msg, "Tools");
          //  };
            // HEALTH → initial toast
            _health = Health.Snapshot;

            var ollama = _health[HealthDomain.Ollama];
            if (ollama.Level == HealthLevel.Unhealthy)
                await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", ollama.Error ?? "Ollama error", "Ollama");
            else if (ollama.Level == HealthLevel.Healthy)
                await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", $"Connected to Ollama ({ollama.Meta?["ServerUrl"]})", "Ollama");

            _healthHandler = async (_, snap) =>
            {
                _health = snap;
                var o = snap[HealthDomain.Ollama];
                if (o.Level == HealthLevel.Unhealthy)
                    await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", o.Error ?? "Ollama error", "Ollama");
                else if (o.Level == HealthLevel.Healthy)
                    await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", $"Connected to Ollama ({o.Meta?["ServerUrl"]})", "Ollama");

                // Optional: show vector-store or database issues similarly if you want.
                await InvokeAsync(StateHasChanged);
            };
            Health.Changed += _healthHandler;


            await JSRuntime.InvokeVoidAsync("GLOBAL.SetOllamaRef", _ref);
        }

        await JSRuntime.InvokeVoidAsync("GLOBAL.HighlightAllPrism");
    }
    // add once in the component/class
    private static readonly System.Collections.Concurrent.ConcurrentDictionary<string, byte>
        _pulling = new(System.StringComparer.OrdinalIgnoreCase);
    private readonly CancellationTokenSource cts = new();



    private async Task<bool> IsInstalledAsync(string model, CancellationToken ct = default)
    {
        // normalize ":latest"
        if (!model.Contains(':')) model += ":latest";
        var local = await ClientState.OllamaClient.ListLocalModelsAsync(ct);
        return local.Any(x => string.Equals(x.Name, model, StringComparison.OrdinalIgnoreCase));
    }
    private async Task PullModelAndNotifyAsync(string model, CancellationToken ct)
    {
        if (await IsInstalledAsync(model, ct))
        {
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", $"{model} already installed", "Ollama"); 
            return;
        }
        if (!_pulling.TryAdd(model, 0))
        {
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", $"{model} is already downloading", "Ollama");
            return;
        }

        try
        {
           

            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", $"Starting download: {model}", "Ollama");

            var req = new OllamaSharp.Models.PullModelRequest { Model = model };
            await foreach (var evt in ClientState.OllamaClient.PullModelAsync(req).WithCancellation(ct).ConfigureAwait(false))
            {
                // no per-tick JS calls; let the loop stream quietly
                // rely on final success + post-check
            }

            // Final verification is the source of truth
            if (await IsInstalledAsync(model, ct))
            {
                await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", $"Download complete: {model}", "Ollama");
            }
            else
            {
                await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", $"Download finished but not installed: {model}", "Ollama");
            }
        }
        catch (OperationCanceledException) { /* optional toast */ }
        catch (Exception ex)
        {
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", $"Failed to download {model}: {ex.Message}", "Ollama");
        }
        finally
        {
            _pulling.TryRemove(model, out _);
            await header!.RefreshModelsAsync();
          //  await InvokeAsync(StateHasChanged); did not helpop
        }
    }

    [JSInvokable]
    public Task PullModelFromLink(string model)
    {
       
        // don’t block the UI thread; run on background
        _ = Task.Run(() => PullModelAndNotifyAsync(model, cts.Token));
        return Task.CompletedTask;
    }

    public void Dispose()
    {
        currentResponseCancellation?.Cancel();
        if (_healthHandler is not null) Health.Changed -= _healthHandler;
        State.OnStatusMessage -= OnStatusMessageHandler;
    }


}
