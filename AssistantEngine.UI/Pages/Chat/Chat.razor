@using System.ComponentModel
@using AssistantEngine.Factories
@using AssistantEngine.Services.Extensions
@using AssistantEngine.Services.Implementation
@using AssistantEngine.UI.Services
@using AssistantEngine.UI.Services.Implementation.Database
@using AssistantEngine.UI.Services.Implementation.Factories
@using AssistantEngine.UI.Services.Implementation.Models.Chat
@using AssistantEngine.UI.Services.Models
@using AssistantEngine.UI.Services.Models.Chat
@using static AssistantEngine.Services.Extensions.ChatMessageExtensions;

@inject NavigationManager Nav
@inject SemanticSearch Search
@implements IDisposable
@inject ChatClientState ClientState
@inject IDatabaseRegistry DbRegistry
@inject IAppHealthService Health
@inject ChatClientFactory ChatFactory
@inject IJSRuntime JSRuntime
@inject IChatRepository ChatRepository


@if (showPageSpinner)
{
    <PageSpinner1>
    </PageSpinner1>
}
@if (showChatMessageSidebar)
                {
<ChatSidebar OnNewChat="@ResetConversationAsync" CurrentSession="@chatSession"
         CurrentSessionChanged="OnSessionChanged"  
         OpenSettingsModalRequested="OpenSettingsModal" />
                }

<OllamaImportModal @ref="_importModal" />
<GlobalSettingsModal @ref="_settingsModal" />


            <div id="chat-container-outer">

                <div class="chat-container-inner">

        <ChatHeader @ref="header" OnToggleEvaluations="ToggleEvaluations" OpenModalRequested="OpenImportModal" OnStateChange="@SwitchModel" OnNewChat="@ResetConversationAsync" OnStateSelected="SwitchModel2" OnToggleChatOptionsSidebar="ToggleChatOptionsSidebar" OnToggleChatMessageSidebar="ToggleChatMessageSidebar" IsSidebarVisible="@showChatOptionsSidebar" />

                    @if (!isIngesting)
                    {
                        <ChatMessageList Messages="@messages" ChatResponse="@chatResponse" InProgressMessage="@currentResponseMessage" IsLoading="@isLoading" IsStreaming="@isStreaming" OnEditSubmit="@OnUserEditSubmit">
                <NoMessagesContent>
                    <img src="_content/AssistantEngine.UI/img/logo-watermark-2.svg" id="inner-logo-main" />
                            </NoMessagesContent>
                        </ChatMessageList>
                    }
                    else
                    {
                        <LoadingSpinner Visible="@isIngesting" Message="Ingesting Data..." />

                    }

                    <div id="chat-container" class="chat-container">
                        <ChatSuggestions OnSelected="@AddUserMessageAsync" @ref="@chatSuggestions" />
                        <ChatInput OnSend="@AddUserMessageAsync" @ref="@chatInput" />

                    </div>
                </div>
                @if (showChatOptionsSidebar)
                {
                    <ChatOptionsSidebar OnStateChange="@SwitchModel" AssistantConfig="@ClientState.Config" class="order-last" />
                }

            </div>


@code {
    private ChatHeader? header;
    private OllamaImportModal? _importModal;
    private GlobalSettingsModal? _settingsModal;
    private DotNetObjectReference<Chat>? _ref;
    Dictionary<string, IDatabase> databaseDict;

    ChatSession chatSession = new();
    private List<ChatMessage> messages = new();

    private SidebarTab current = SidebarTab.Chats;

    void HandleTabChanged(SidebarTab tab)
    {
        current = tab; // parent decides what to render
        StateHasChanged();
    }
    private void ToggleEvaluations()
    {

    }
    private async Task SwitchModel()
    {
        await ChatRepository.SaveAsync(chatSession);
        await OnParametersSetAsync();
        await InvokeAsync(StateHasChanged);

    }
    private void OpenSettingsModal() => _settingsModal?.Open();
    private void OpenImportModal() => _importModal?.OpenDownloadModal();
    private void SetupChatState()
    {
        databaseDict = DbRegistry.All.ToDictionary(x => x.Key, x => x.Value);

        // only add system prompt once
        if (messages.Count > 0)
        {
            messages.Clear();
        }

        if (messages.Count == 0)
            messages.Add(new(ChatRole.System, ClientState.Config.SystemPrompt));

        Console.WriteLine(chatOptions.Tools);
    }


    private async Task SwitchModel2()
    {


    }

    // NEW: stream tokens into currentResponseMessage in real time
    private async Task GenerateAssistantResponseStreamingAsync(List<ChatMessage> filteredMessages)
    {
        currentResponseCancellation?.Dispose();
        currentResponseCancellation = new();
        isLoading = true;

        // wall-clock start
        var startTime = DateTime.UtcNow;
        DateTime? firstTokenTime = null;

        // prepare the in-progress assistant message (bound to ChatMessageList via InProgressMessage)
        currentResponseMessage = new ChatMessage
        {
            MessageId = Guid.NewGuid().ToString(),
            Role = ChatRole.Assistant
        };

        try
        {
            var updatesBuffer = new List<ChatResponseUpdate>();
            var mergedAdditional = new Microsoft.Extensions.AI.AdditionalPropertiesDictionary();

            await foreach (var update in ChatClient
                .GetStreamingResponseAsync(filteredMessages, chatOptions, currentResponseCancellation.Token)
                .ConfigureAwait(false))
            {
                isStreaming = true;
                updatesBuffer.Add(update);

                // merge AdditionalProperties as they arrive (last-write-wins)
                if (update?.AdditionalProperties is not null)
                    foreach (var kv in update.AdditionalProperties)
                        mergedAdditional[kv.Key] = kv.Value;

                var contents = update?.Contents ?? [];
                foreach (var c in contents)
                {
                    // mark first token time on first piece of content (text or otherwise)
                    if (!firstTokenTime.HasValue) firstTokenTime = DateTime.UtcNow;

                    if (c is TextContent tc)
                    {
                        var lastText = currentResponseMessage!.Contents.OfType<TextContent>().LastOrDefault();
                        if (lastText is null) currentResponseMessage!.Contents.Add(new TextContent(tc.Text));
                        else lastText.Text += tc.Text;
                    }
                    else
                    {
                        currentResponseMessage!.Contents.Add(c);
                        if (c.GetType().Name.Contains("ToolCall", StringComparison.OrdinalIgnoreCase))
                            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.info", "Running tool…", "Tools");
                        if (c.GetType().Name.Contains("ToolResult", StringComparison.OrdinalIgnoreCase))
                            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.success", "Tool finished.", "Tools");
                    }

                    ChatMessageItem.NotifyChanged(currentResponseMessage!);
                }

                await InvokeAsync(StateHasChanged);
            }

            // build ChatResponse from updates
            async IAsyncEnumerable<ChatResponseUpdate> Replay()
            {
                foreach (var u in updatesBuffer) yield return u;
            }
            chatResponse = await Replay().ToChatResponseAsync(currentResponseCancellation.Token);

            // --- ensure AdditionalProperties contains required durations as per your definitions ---
            chatResponse.AdditionalProperties ??= new Microsoft.Extensions.AI.AdditionalPropertiesDictionary();

            // merge what we collected during streaming
            foreach (var kv in mergedAdditional)
                chatResponse.AdditionalProperties[kv.Key] = kv.Value;

            var finishTime = DateTime.UtcNow;
            var totalAll = finishTime - startTime;

            // total_duration_all: whole wall time
            if (!chatResponse.AdditionalProperties.ContainsKey("total_duration_all"))
                chatResponse.AdditionalProperties["total_duration_all"] = totalAll;

            // load_duration: start -> first token (or totalAll if no tokens ever arrived)
            var loadDuration = firstTokenTime.HasValue ? (firstTokenTime.Value - startTime) : totalAll;
            if (!chatResponse.AdditionalProperties.ContainsKey("load_duration"))
                chatResponse.AdditionalProperties["load_duration"] = loadDuration;

            // eval_duration: first token -> finish (zero if no tokens)
            var evalDuration = firstTokenTime.HasValue ? (finishTime - firstTokenTime.Value) : TimeSpan.Zero;
            if (!chatResponse.AdditionalProperties.ContainsKey("eval_duration"))
                chatResponse.AdditionalProperties["eval_duration"] = evalDuration;

            // total_duration (model time): if missing, use eval_duration
            if (!chatResponse.AdditionalProperties.ContainsKey("total_duration"))
                chatResponse.AdditionalProperties["total_duration"] = evalDuration;

            // tool_duration: keep your existing approach (total_all - total_duration), never negative
            if (!chatResponse.AdditionalProperties.ContainsKey("tool_duration"))
            {
                var toolDuration = TimeSpan.Zero;
                chatResponse.AdditionalProperties["tool_duration"] = toolDuration;
            }
            // --- end ensure durations ---

            messages.Add(currentResponseMessage!);
            chatSession.Messages = messages;
            currentResponseMessage = null;
            isStreaming = false;
            isLoading = false;

            chatSuggestions?.Update(messages);
            await ChatRepository.SaveAsync(chatSession);

            if (chatSession.DefaultTitle())
                await SetChatMessageTitle();
        }
        catch (OperationCanceledException)
        {
            isLoading = false;
        }
        catch (Exception ex)
        {
            isLoading = false;
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", ex.Message, "Streaming");
        }
    }



    private IChatClient ChatClient => ChatFactory(ClientState.Config.AssistantModel.ModelId);
    private IChatClient MiniClient => ChatFactory(ClientState.Config.MiniTaskModel.ModelId);
    AssistantConfig CurrentConfig => ClientState.Config;
    private bool isIngesting => !ClientState.IngestionFinished;
    //IChatClient ChatClient => (IChatClient) ClientState.Client; testing with this removed


    protected override void OnInitialized()
    {
        ClientState.OnLoaderMessage += (v, m) =>
        {

            InvokeAsync(StateHasChanged);
        };
    }

    private async Task OnSessionChanged(ChatSession session)
    {
        CancelAnyCurrentResponse();
        chatSession = session;
        messages = chatSession.Messages?.ToList() ?? new List<ChatMessage>();
        await InvokeAsync(StateHasChanged);

    }
    private ChatOptions chatOptions => ClientState.ChatOptions;

    private CancellationTokenSource? currentResponseCancellation;
    private ChatMessage? currentResponseMessage;
    private ChatResponse? chatResponse;
    private ChatInput? chatInput;
    private ChatSuggestions? chatSuggestions;

    private bool showPageSpinner = false;
    private bool showChatOptionsSidebar = true;
    private bool showChatMessageSidebar = true;
    private bool isLoading = false;
    private bool isStreaming = false;

    private void ToggleChatOptionsSidebar()
    {
        showChatOptionsSidebar = !showChatOptionsSidebar;

    }
    private void ToggleChatMessageSidebar()
    {
        showChatMessageSidebar = !showChatMessageSidebar;

    }

    // — then call it here (and drop OnInitialized entirely)
    // — then call it here (and drop OnInitialized entirely)
    protected override async Task OnParametersSetAsync()
    {
        try
        {
            SetupChatState();
            // await base.OnParametersSetAsync();
            await base.OnParametersSetAsync();
        }
        catch (Exception ex)
        {
            Console.WriteLine(ex.Message);
            Console.WriteLine(ex.StackTrace);
        }

    }



    private OllamaSharp.Models.Model currentModel;
    // NEW: centralize assistant generation so edits can reuse it
    private async Task GenerateAssistantResponseAsync(List<ChatMessage> filteredMessages)
    {
        //currentResponseCancellation ??= new();
        currentResponseCancellation?.Dispose();
        currentResponseCancellation = new();   // ✅ always fresh
        DateTime startTime = DateTime.UtcNow;



        var response = await ChatClient.GetResponseAsync(filteredMessages, chatOptions, currentResponseCancellation.Token);
        var merged = new List<ChatMessage>();
        ChatMessage? buffer = null;

        foreach (var m in response.Messages)
        {
            if (m.Role == ChatRole.Assistant)
            {
                if (buffer == null)
                {
                    buffer = new ChatMessage
                    {
                        MessageId = Guid.NewGuid().ToString(),
                        Role = ChatRole.Assistant
                    };
                    foreach (var c in m.Contents ?? Enumerable.Empty<AIContent>())
                        buffer.Contents.Add(c);
                }
                else
                {
                    foreach (var c in m.Contents ?? Enumerable.Empty<AIContent>())
                        buffer.Contents.Add(c);
                }
            }
            else if (m.Role == ChatRole.User)
            {
                if (buffer != null) { merged.Add(buffer); buffer = null; }
                merged.Add(new ChatMessage
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Role = m.Role,
                    Contents = new List<AIContent>(m.Contents ?? [])
                });
            }
            else
            {
                merged.Add(new ChatMessage
                {
                    MessageId = Guid.NewGuid().ToString(),
                    Role = m.Role,
                    Contents = new List<AIContent>(m.Contents ?? [])
                });
            }
        }
        if (buffer != null) merged.Add(buffer);

        foreach (var mm in merged)
        {
            if (string.IsNullOrEmpty(mm.MessageId) || messages.Any(x => x.MessageId == mm.MessageId))
                mm.MessageId = Guid.NewGuid().ToString();

            messages.Add(mm.Clone());
        }

        DateTime finishTime = DateTime.UtcNow;
        TimeSpan duration = finishTime - startTime;
        if (response.AdditionalProperties != null)
        {
            response.AdditionalProperties.Add("total_duration_all", duration);
            if (response.AdditionalProperties.TryGetValue("total_duration", out var td) && TimeSpan.TryParse(td?.ToString(), out var totalDurationAnalysis))
                response.AdditionalProperties.Add("tool_duration", duration - totalDurationAnalysis);
        }

        isLoading = false;

        chatSession.Messages = messages;
        chatResponse = response;

        if (chatSession.DefaultTitle())
            await SetChatMessageTitle();

        chatSuggestions?.Update(messages);
        await ChatRepository.SaveAsync(chatSession);
    }

    // UPDATED: use the helper above
    private async Task AddUserMessageAsync(ChatMessage userMessage)
    {
        var o = Health.Get(HealthDomain.Ollama);
        if (o.Level != HealthLevel.Healthy)
        {
            await JSRuntime.InvokeVoidAsync("GLOBAL.toastrInterop.error", o.Error ?? "Ollama not reachable.", "Chat");
            return;
        }

        CancelAnyCurrentResponse();

        messages.Add(userMessage);
        chatSuggestions?.Clear();
        await chatInput!.FocusAsync();

        currentResponseCancellation = new();
        isLoading = true;
        await InvokeAsync(StateHasChanged);

        var filteredMessages = FilterChatMessages(messages);
        await GenerateAssistantResponseStreamingAsync(filteredMessages);
    }

    // NEW: handle inline user-message edit → truncate future → regenerate
    private async Task OnUserEditSubmit((ChatMessage message, string newText) edit)
    {
        var (msg, newText) = edit;

        CancelAnyCurrentResponse();

        var idx = messages.FindIndex(m => m.MessageId == msg.MessageId);
        if (idx < 0) idx = messages.IndexOf(msg);
        if (idx < 0) return;

        // update the edited user message
        messages[idx] = new (ChatRole.User, newText);
        try
        {
            // messages[idx].Contents?.Clear();
            // messages[idx].Contents?.Add(new TextContent(newText));
        }
        catch { /* safe no-op if types differ */ }

        // drop everything after the edited message
        if (idx < messages.Count - 1)
            messages.RemoveRange(idx + 1, messages.Count - (idx + 1));

        chatResponse = null;
        isLoading = true;
        await InvokeAsync(StateHasChanged);

        var filtered = FilterChatMessages(messages);
        await GenerateAssistantResponseStreamingAsync(filtered);
    }

    private List<ChatMessage> FilterChatMessages(List<ChatMessage> messagesToFilter)
    {
        var filteredMessages = messagesToFilter;
        ChatOptions chatOptions = new ChatOptions();


        if (!ClientState.Config.PersistThoughtHistory)
        {
            filteredMessages.RemoveThinkMessages();
        }

        return filteredMessages;
    }


    private async Task SetChatMessageTitle()
    {
        try
        {
            var miniOptions = ClientState.Config.ModelOptions.First(m => m.Key == "MiniTask").Options;
            List<ChatMessage> messagesx = new();
            string prompt = $"Output a maximum three word title for text you receive. Only ever output these words.";
            string userMessage = messages.First(x => x.Role == ChatRole.User).Text;
            messagesx.Add(new(ChatRole.System, prompt));
            messagesx.Add(new(ChatRole.User, userMessage));
            var response = await MiniClient.GetResponseAsync(messagesx, miniOptions);
            string title = ChatMessageExtensions.RemoveThinkTags(response.Messages.First(x => x.Role == ChatRole.Assistant).Text);
            chatSession.Title = title;
            await ChatRepository.SaveAsync(chatSession);
            await InvokeAsync(StateHasChanged);
        }catch(Exception ex)
        {
            Console.WriteLine("Error Setting Chat Message Title");
            Console.WriteLine(ex.Message);
            Console.WriteLine(ex.StackTrace);
        }

    }



    private Task SwitchModel(OllamaSharp.Models.Model model)
    {
        currentModel = model;
        // maybe restart the chat or just show the new model name
        return Task.CompletedTask;
    }
    private void CancelAnyCurrentResponse()
    {
        // If a response was cancelled while streaming, include it in the conversation so it's not lost
        if (currentResponseMessage is not null)
        {
            messages.Add(currentResponseMessage);
        }
        isLoading = false;
        chatResponse = null;
        currentResponseCancellation?.Cancel();
        currentResponseMessage = null;
    }

    private async Task ResetConversationAsync() //clear active here
    {
        try{
            chatSession = new();
            CancelAnyCurrentResponse();
            messages.Clear();
            messages.Add(new(ChatRole.System, ClientState.Config.SystemPrompt));
            chatSuggestions?.Clear(); chatResponse = null;
            await chatInput!.FocusAsync();
        }catch(Exception ex)
        {
            Console.WriteLine(ex.Message);Console.WriteLine(ex.StackTrace);
        }

    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        await JSRuntime.InvokeVoidAsync("GLOBAL.HighlightAllPrism");
    }

    // add once in the component/class
    private static readonly System.Collections.Concurrent.ConcurrentDictionary<string, byte>
        _pulling = new(System.StringComparer.OrdinalIgnoreCase);
    private readonly CancellationTokenSource cts = new();





    public void Dispose()
    {
        currentResponseCancellation?.Cancel();
       // if (_healthHandler is not null) Health.Changed -= _healthHandler;
        ///ClientState.OnStatusMessage -= OnStatusMessageHandler;
    }


}
